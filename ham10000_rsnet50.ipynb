{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ef38297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.498191Z",
     "start_time": "2025-02-02T10:30:03.826727Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581c481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c520b39",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6420e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.512265Z",
     "start_time": "2025-02-02T10:30:07.499390Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"data/HAM10000_metadata.csv\")\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9d61f",
   "metadata": {},
   "source": [
    "### Link Metadata to Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cb48301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.515109Z",
     "start_time": "2025-02-02T10:30:07.513108Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_path(image_id):\n",
    "    if os.path.exists(os.path.join(image_dir_1, image_id + \".jpg\")):\n",
    "        return os.path.join(image_dir_1, image_id + \".jpg\")\n",
    "    elif os.path.exists(os.path.join(image_dir_2, image_id + \".jpg\")):\n",
    "        return os.path.join(image_dir_2, image_id + \".jpg\")\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0eb76196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.564998Z",
     "start_time": "2025-02-02T10:30:07.516728Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dir_1 = \"data/HAM10000_images_part_1/\"\n",
    "image_dir_2 = \"data/HAM10000_images_part_2/\"\n",
    "\n",
    "df = meta\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(get_image_path)\n",
    "\n",
    "missing_images = df[df[\"image_path\"].isna()]\n",
    "print(f\"Missing images: {len(missing_images)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3c1c8",
   "metadata": {},
   "source": [
    "### Understand Class Distribution\n",
    "\n",
    "- Actinic keratoses and intraepithelial carcinoma / Bowen's disease (**akiec**), \n",
    "- basal cell carcinoma (**bcc**), \n",
    "- benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, (**bkl**), \n",
    "- dermatofibroma (**df**), \n",
    "- melanoma (**mel**), \n",
    "- melanocytic nevi (**nv**) and \n",
    "- vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, (**vasc**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e17539e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.646717Z",
     "start_time": "2025-02-02T10:30:07.565733Z"
    }
   },
   "outputs": [],
   "source": [
    "class_counts = df[\"dx\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Class Distribution in the HAM10000 Dataset\")\n",
    "plt.xlabel(\"Skin Lesion Type\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754fadb",
   "metadata": {},
   "source": [
    "We'll have to factor in this during the modeling iterations and perhaps add a method to account for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419db13",
   "metadata": {},
   "source": [
    "### Data Preprocessing (Resizing & Normalising) and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d466b602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.649814Z",
     "start_time": "2025-02-02T10:30:07.647812Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for efficiency\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip images randomly (lesions don't have strict orientation)\n",
    "    transforms.RandomRotation(degrees=20),  # Slight rotation (lesions appear at different angles)\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Vary lighting conditions\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Small position shifts\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6253a329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.652931Z",
     "start_time": "2025-02-02T10:30:07.650604Z"
    }
   },
   "outputs": [],
   "source": [
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx][\"image_path\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.dataframe.iloc[idx][\"dx\"]\n",
    "\n",
    "        label_map = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "        label_idx = label_map[label]\n",
    "\n",
    "        return image, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44404701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.659271Z",
     "start_time": "2025-02-02T10:30:07.653611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub = df.sample(2000)\n",
    "sub = df\n",
    "\n",
    "unique_lesions = sub[\"lesion_id\"].unique()\n",
    "train_lesions, val_lesions = train_test_split(unique_lesions, test_size=0.2, random_state=42)\n",
    "train_df = sub[sub[\"lesion_id\"].isin(train_lesions)]\n",
    "val_df = sub[sub[\"lesion_id\"].isin(val_lesions)]\n",
    "\n",
    "print(f\"Train Set: {len(train_df)} images\")\n",
    "print(f\"Validation Set: {len(val_df)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6fcc045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.662781Z",
     "start_time": "2025-02-02T10:30:07.660084Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b1c6f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:07.668915Z",
     "start_time": "2025-02-02T10:30:07.666230Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = HAM10000Dataset(train_df, transform=transform)\n",
    "val_dataset = HAM10000Dataset(val_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb33c14",
   "metadata": {},
   "source": [
    "### Model Selection and Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48257e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:08.714683Z",
     "start_time": "2025-02-02T10:30:07.669985Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "# model = models.resnet34(pretrained=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af56f956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:08.724025Z",
     "start_time": "2025-02-02T10:30:08.715505Z"
    }
   },
   "outputs": [],
   "source": [
    "class_counts = df[\"dx\"].value_counts().sort_index()\n",
    "total_samples = len(df)\n",
    "\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)  # inverse frequency\n",
    "class_weights = torch.tensor(class_weights.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# loss function with class weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "print(\"Class Weights (Used in Loss Function):\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "422fe434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:08.727307Z",
     "start_time": "2025-02-02T10:30:08.724997Z"
    }
   },
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-6)\n",
    "# optimiser = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "# lr scheduler - reduces LR when validation loss plateaus\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80ab69",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d663fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:30:08.731805Z",
     "start_time": "2025-02-02T10:30:08.728283Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83ac6776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:41:33.803501Z",
     "start_time": "2025-02-02T10:41:33.405240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a batch of images: torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(\"Loaded a batch of images:\", images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ac09def",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:17:25.898594Z",
     "start_time": "2025-02-02T10:41:36.575903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10] - Time: 214.51s\n",
      "Train Loss: 0.4091, Train Acc: 79.72%\n",
      "Val Loss: 0.8199, Val Acc: 74.96%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10] - Time: 209.10s\n",
      "Train Loss: 0.3945, Train Acc: 81.09%\n",
      "Val Loss: 0.8409, Val Acc: 73.49%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10] - Time: 210.06s\n",
      "Train Loss: 0.3406, Train Acc: 82.72%\n",
      "Val Loss: 0.6929, Val Acc: 77.32%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10] - Time: 213.36s\n",
      "Train Loss: 0.3364, Train Acc: 84.25%\n",
      "Val Loss: 0.7150, Val Acc: 75.89%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10] - Time: 209.02s\n",
      "Train Loss: 0.2704, Train Acc: 85.52%\n",
      "Val Loss: 0.8184, Val Acc: 74.28%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10] - Time: 221.34s\n",
      "Train Loss: 0.2503, Train Acc: 86.07%\n",
      "Val Loss: 0.7677, Val Acc: 79.72%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10] - Time: 218.66s\n",
      "Train Loss: 0.1921, Train Acc: 88.83%\n",
      "Val Loss: 0.7344, Val Acc: 78.29%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8/10] - Time: 216.99s\n",
      "Train Loss: 0.2105, Train Acc: 88.19%\n",
      "Val Loss: 0.7366, Val Acc: 80.60%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9/10] - Time: 217.91s\n",
      "Train Loss: 0.2630, Train Acc: 86.97%\n",
      "Val Loss: 0.6332, Val Acc: 81.87%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10/10] - Time: 218.32s\n",
      "Train Loss: 0.1866, Train Acc: 90.12%\n",
      "Val Loss: 0.7230, Val Acc: 79.47%\n",
      "--------------------------------------------------\n",
      "Training complete. Best validation accuracy: 81.87163155316021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "save_path = \"best_renet34_10epochs_notpretrained.pth\"\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/HAM10000_resnet50\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    train_loss, train_acc = train_model(model, train_loader, criterion, optimiser, device, epoch)\n",
    "    val_loss, val_acc = validate_model(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Accuracy/Validation\", val_acc, epoch)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] - Time: {epoch_time:.2f}s\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1} ðŸš¨\")\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "print(\"Training complete. Best validation accuracy:\", best_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed612f",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13288ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:32:34.476965Z",
     "start_time": "2025-02-02T11:32:34.458240Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "def classification_report_df(true_labels, predicted_labels, class_names):\n",
    "    report_dict = classification_report(true_labels, predicted_labels, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_df = report_df.round(4)\n",
    "    \n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10e8cb0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:32:59.387304Z",
     "start_time": "2025-02-02T11:32:35.049589Z"
    }
   },
   "outputs": [],
   "source": [
    "true_labels, predicted_labels = evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "697ccc29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:33:08.392060Z",
     "start_time": "2025-02-02T11:33:08.330247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.6029</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>68.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>132.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkl</th>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>244.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.6176</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>34.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0.5119</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>225.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>1302.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasc</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>36.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.6956</td>\n",
       "      <td>2041.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.8236</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>2041.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score    support\n",
       "akiec            0.5857  0.6029    0.5942    68.0000\n",
       "bcc              0.7748  0.6515    0.7078   132.0000\n",
       "bkl              0.6226  0.8115    0.7046   244.0000\n",
       "df               0.5250  0.6176    0.5676    34.0000\n",
       "mel              0.5119  0.6711    0.5808   225.0000\n",
       "nv               0.9424  0.8418    0.8892  1302.0000\n",
       "vasc             0.7500  0.9167    0.8250    36.0000\n",
       "accuracy         0.7967  0.7967    0.7967     0.7967\n",
       "macro avg        0.6732  0.7304    0.6956  2041.0000\n",
       "weighted avg     0.8236  0.7967    0.8051  2041.0000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "report_df = classification_report_df(true_labels, predicted_labels, class_names)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab16a86b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:33:14.835746Z",
     "start_time": "2025-02-02T11:33:14.808187Z"
    }
   },
   "outputs": [],
   "source": [
    "report_df.to_csv(\"resnet50_10epochs_class_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dfbab",
   "metadata": {},
   "source": [
    "### Inference - on the test set\n",
    "- Not interested right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8255e2c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:33:17.844079Z",
     "start_time": "2025-02-02T11:33:17.830781Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, device):\n",
    "    model.eval()\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "    \n",
    "    class_map = {0: 'akiec', 1: 'bcc', 2: 'bkl', 3: 'df', 4: 'mel', 5: 'nv', 6: 'vasc'}\n",
    "    return class_map[predicted_class.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "978cad23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:33:20.758386Z",
     "start_time": "2025-02-02T11:33:19.261814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bkl'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"data/HAM10000_images_part_1/ISIC_0027419.jpg\"\n",
    "predicted_class = predict_image(image_path, model, device)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b485e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e30d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94c24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5ce26",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-02T10:30:03.845Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1k; bs 64 - 1m 48.4s\n",
    "# 2k; bs 64 - 3m 56s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b122c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b3a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pm",
   "language": "python",
   "name": "pm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "337.778px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
